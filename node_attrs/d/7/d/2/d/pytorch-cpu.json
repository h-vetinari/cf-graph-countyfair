{
 "archived": false,
 "branch": "main",
 "conda-forge.yml": {
  "azure": {
   "free_disk_space": true,
   "settings_linux": {
    "timeoutInMinutes": 1
   },
   "settings_win": {
    "variables": {
     "CONDA_BLD_PATH": "C:\\\\bld\\\\"
    }
   }
  },
  "build_platform": {
   "linux_aarch64": "linux_64",
   "osx_arm64": "osx_64"
  },
  "conda_build": {
   "pkg_format": "2"
  },
  "conda_forge_output_validation": true,
  "github": {
   "branch_name": "main",
   "tooling_branch_name": "main"
  },
  "github_actions": {
   "self_hosted": true,
   "timeout_minutes": 1080,
   "triggers": [
    "push",
    "pull_request"
   ]
  },
  "provider": {
   "linux_64": "github_actions",
   "linux_aarch64": "azure",
   "win_64": "github_actions"
  },
  "test": "native_and_emulated"
 },
 "feedstock_name": "pytorch-cpu",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "description": "PyTorch is a Python package that provides two high-level features:\n  - Tensor computation (like NumPy) with strong GPU acceleration\n  - Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n",
   "dev_url": "https://github.com/pytorch/pytorch",
   "doc_url": "https://pytorch.org/docs/",
   "home": "https://pytorch.org/",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": [
    "LICENSE",
    "NOTICE",
    "third_party/CMake/Copyright.txt"
   ],
   "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
  },
  "build": {
   "detect_binary_files_with_prefix": false,
   "ignore_run_exports": [
    "python *",
    "numpy *",
    "libmagma_sparse"
   ],
   "ignore_run_exports_from": [
    "python *",
    "numpy *"
   ],
   "number": "312",
   "run_exports": [
    "libtorch"
   ],
   "skip": true,
   "string": "cuda126_mkl_h1234567_312"
  },
  "extra": {
   "feedstock-name": "pytorch-cpu",
   "recipe-maintainers": [
    "baszalmstra",
    "benjaminrwilson",
    "beckermr",
    "h-vetinari",
    "hmaarrfk",
    "jeongseok-meta",
    "mgorny",
    "sodre",
    "Tobias-Fischer"
   ]
  },
  "outputs": [
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py39_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"linux\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cpu_generic*12"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cuda126_generic_py39_h1234567_212"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "cuda-version 12.6",
      "nvtx-c",
      "magma",
      "cuda-driver-dev",
      "cuda-cudart-dev",
      "cuda-cupti-dev",
      "cuda-nvrtc-dev",
      "cuda-nvtx-dev",
      "cuda-nvml-dev",
      "cuda-profiler-api",
      "cusparselt",
      "libcublas-dev",
      "libcudss-dev",
      "libcufile-dev",
      "libcufft-dev",
      "libcurand-dev",
      "libcusolver-dev",
      "libcusparse-dev",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "cudnn",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "__cuda",
      "libtorch 2.5.1",
      "setuptools",
      "triton 3.1.0"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.5.1",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
      "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
      "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"12.6\"",
      "export MATRIX_GPU_ARCH_TYPE=\"cuda\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"linux\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda126_generic_h1234567_212",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cuda*_generic*212"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py39_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "libgomp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"linux\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cpu_mkl*112"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cuda126_mkl_py39_h1234567_312"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "cuda-version 12.6",
      "nvtx-c",
      "magma",
      "cuda-driver-dev",
      "cuda-cudart-dev",
      "cuda-cupti-dev",
      "cuda-nvrtc-dev",
      "cuda-nvtx-dev",
      "cuda-nvml-dev",
      "cuda-profiler-api",
      "cusparselt",
      "libcublas-dev",
      "libcudss-dev",
      "libcufile-dev",
      "libcufft-dev",
      "libcurand-dev",
      "libcusolver-dev",
      "libcusparse-dev",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "libgomp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "libblas * *mkl",
      "cudnn",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "__cuda",
      "libtorch 2.5.1",
      "setuptools",
      "triton 3.1.0"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.5.1",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
      "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
      "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"12.6\"",
      "export MATRIX_GPU_ARCH_TYPE=\"cuda\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"linux\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda126_mkl_h1234567_312",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cuda*_mkl*312"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   }
  ],
  "package": {
   "name": "libtorch",
   "version": "2.5.1"
  },
  "requirements": {
   "build": [
    "c_stdlib_stub",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "libgomp",
    "cmake",
    "ninja",
    "libprotobuf",
    "protobuf",
    "make",
    "rsync",
    "cuda_compiler_stub"
   ],
   "host": [
    "python 3.12",
    "numpy *",
    "pip",
    "setuptools",
    "pyyaml",
    "requests",
    "six",
    "libblas",
    "libcblas",
    "liblapack",
    "libgomp",
    "libabseil",
    "libprotobuf",
    "sleef",
    "libuv",
    "pkg-config",
    "typing_extensions",
    "pybind11",
    "eigen",
    "zlib",
    "cudnn",
    "nccl",
    "magma",
    "cuda-version 12.6",
    "nvtx-c",
    "cuda-driver-dev",
    "cuda-cudart-dev",
    "cuda-cupti-dev",
    "cuda-nvrtc-dev",
    "cuda-nvtx-dev",
    "cuda-nvml-dev",
    "cuda-profiler-api",
    "cusparselt",
    "libcublas-dev",
    "libcudss-dev",
    "libcufile-dev",
    "libcufft-dev",
    "libcurand-dev",
    "libcusolver-dev",
    "libcusparse-dev",
    "mkl-devel <2025",
    "libcblas * *_mkl"
   ],
   "run": [
    "cudnn",
    "libblas * *mkl"
   ],
   "run_constrained": [
    "pytorch-cpu ==2.5.1",
    "pytorch-gpu ==99999999",
    "pytorch 2.5.1 cpu_generic_*_12",
    "openblas * openmp_*",
    "pytorch-gpu ==2.5.1",
    "pytorch-cpu ==99999999",
    "pytorch 2.5.1 cuda126_generic_*_212",
    "pytorch 2.5.1 cpu_mkl_*_112",
    "pytorch 2.5.1 cuda126_mkl_*_312"
   ]
  },
  "schema_version": 0,
  "source": {
   "patches": [
    "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
    "patches/0002-Help-find-numpy.patch",
    "patches/0003-Add-USE_SYSTEM_NVTX-option-138287.patch",
    "patches/0004-Update-sympy-version.patch",
    "patches/0006-fix-3.13-pickle-error-in-serialization.py-136034.patch",
    "patches/0007-Allow-users-to-overwrite-ld-with-environment-variabl.patch",
    "patches/0008-Allow-overriding-CUDA-related-paths.patch",
    "patches/0009-Fix-test-test_linalg.py-for-NumPy-2-136800.patch",
    "patches/0010-Fixes-NumPy-2-test-failures-in-test_torch.py-137740.patch",
    "patches/0011-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
    "patches/0012-fix-issue-142484.patch",
    "patches/0013-Fix-FindOpenBLAS.patch",
    "patches/0014-CD-Enable-Python-3.13-on-windows-138095.patch",
    "patches/0015-simplify-torch.utils.cpp_extension.include_paths-use.patch",
    "patches/0016-point-include-paths-to-PREFIX-include.patch",
    "patches/0017-Add-conda-prefix-to-inductor-include-paths.patch",
    "patches/0018-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
    "patches/0020-make-library-name-in-test_mutable_custom_op_fixed_la.patch",
    "patches/0021-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
    "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
   ],
   "sha256": "740eb5fff95e33cfe699bad43be83523f569c7cc7f9c285c2a255416443dd266",
   "url": "https://github.com/pytorch/pytorch/releases/download/v2.5.1/pytorch-v2.5.1.tar.gz"
  },
  "test": {
   "commands": [
    "test -f $PREFIX/lib/libc10.so",
    "test -f $PREFIX/lib/libshm.so",
    "test -f $PREFIX/lib/libtorch.so",
    "test -f $PREFIX/lib/libtorch_cpu.so",
    "test -f $PREFIX/lib/libtorch_global_deps.so",
    "test -f $PREFIX/share/cmake/Torch/TorchConfig.cmake",
    "cd cmake_test",
    "cmake -GNinja -DCMAKE_CXX_STANDARD=17 $CMAKE_ARGS .",
    "test -f $PREFIX/lib/libtorch_cuda_linalg.so",
    "test -f $PREFIX/lib/libc10_cuda.so",
    "test -f $PREFIX/lib/libcaffe2_nvrtc.so",
    "test -f $PREFIX/lib/libtorch_cuda.so"
   ],
   "files": [
    "cmake_test/"
   ],
   "requires": [
    "cxx_compiler_stub",
    "cmake",
    "ninja",
    "pkg-config",
    "cuda_compiler_stub",
    "cuda-nvrtc-dev"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "c_stdlib_stub",
    "cmake",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "libgomp",
    "libprotobuf",
    "make",
    "ninja",
    "protobuf",
    "python",
    "rsync"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cuda-cudart-dev",
    "cuda-cupti-dev",
    "cuda-driver-dev",
    "cuda-nvml-dev",
    "cuda-nvrtc-dev",
    "cuda-nvtx-dev",
    "cuda-profiler-api",
    "cuda-version",
    "cudnn",
    "cusparselt",
    "eigen",
    "libabseil",
    "libblas",
    "libcblas",
    "libcublas-dev",
    "libcudss-dev",
    "libcufft-dev",
    "libcufile-dev",
    "libcurand-dev",
    "libcusolver-dev",
    "libcusparse-dev",
    "libgomp",
    "liblapack",
    "libprotobuf",
    "libtorch",
    "libuv",
    "magma",
    "mkl-devel",
    "nccl",
    "numpy",
    "nvtx-c",
    "pip",
    "pkg-config",
    "pybind11",
    "python",
    "pyyaml",
    "requests",
    "setuptools",
    "six",
    "sleef",
    "typing_extensions",
    "zlib"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "__cuda",
    "cudnn",
    "filelock",
    "fsspec",
    "jinja2",
    "libblas",
    "libtorch",
    "networkx",
    "nomkl",
    "pybind11",
    "python",
    "pytorch",
    "setuptools",
    "sympy",
    "triton",
    "typing_extensions"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "boto3",
    "c_compiler_stub",
    "cmake",
    "cuda-nvrtc-dev",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "expecttest",
    "hypothesis",
    "ninja",
    "pip",
    "pkg-config",
    "pydot",
    "pytest",
    "pytest-flakefinder",
    "pytest-rerunfailures",
    "pytest-xdist",
    "tabulate",
    "xmlrunner"
   ]
  }
 },
 "linux_aarch64_meta_yaml": {
  "about": {
   "description": "PyTorch is a Python package that provides two high-level features:\n  - Tensor computation (like NumPy) with strong GPU acceleration\n  - Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n",
   "dev_url": "https://github.com/pytorch/pytorch",
   "doc_url": "https://pytorch.org/docs/",
   "home": "https://pytorch.org/",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": [
    "LICENSE",
    "NOTICE",
    "third_party/CMake/Copyright.txt"
   ],
   "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
  },
  "build": {
   "detect_binary_files_with_prefix": false,
   "ignore_run_exports": [
    "python *",
    "numpy *",
    "libmagma_sparse"
   ],
   "ignore_run_exports_from": [
    "python *",
    "numpy *"
   ],
   "number": "212",
   "run_exports": [
    "libtorch"
   ],
   "skip": true,
   "string": "cuda126_generic_h1234567_212"
  },
  "extra": {
   "feedstock-name": "pytorch-cpu",
   "recipe-maintainers": [
    "baszalmstra",
    "benjaminrwilson",
    "beckermr",
    "h-vetinari",
    "hmaarrfk",
    "jeongseok-meta",
    "mgorny",
    "sodre",
    "Tobias-Fischer"
   ]
  },
  "outputs": [
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py39_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"linux\"",
      "export OMP_NUM_THREADS=4",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cpu_generic*12"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cuda126_generic_py39_h1234567_212"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "cuda-version 12.6",
      "nvtx-c",
      "magma",
      "cuda-driver-dev",
      "cuda-cudart-dev",
      "cuda-cupti-dev",
      "cuda-nvrtc-dev",
      "cuda-nvtx-dev",
      "cuda-nvml-dev",
      "cuda-profiler-api",
      "cusparselt",
      "libcublas-dev",
      "libcudss-dev",
      "libcufile-dev",
      "libcufft-dev",
      "libcurand-dev",
      "libcusolver-dev",
      "libcusparse-dev",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "cudnn",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "__cuda",
      "libtorch 2.5.1",
      "setuptools",
      "triton 3.1.0"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.5.1",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"linux\"",
      "export OMP_NUM_THREADS=4",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda126_generic_h1234567_212",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cuda*_generic*212"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   }
  ],
  "package": {
   "name": "libtorch",
   "version": "2.5.1"
  },
  "requirements": {
   "build": [
    "c_stdlib_stub",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "libgomp",
    "cmake",
    "ninja",
    "libprotobuf",
    "protobuf",
    "make",
    "rsync",
    "cuda_compiler_stub"
   ],
   "host": [
    "python 3.12",
    "numpy *",
    "pip",
    "setuptools",
    "pyyaml",
    "requests",
    "six",
    "libblas",
    "libcblas",
    "liblapack",
    "libgomp",
    "libabseil",
    "libprotobuf",
    "sleef",
    "libuv",
    "pkg-config",
    "typing_extensions",
    "pybind11",
    "eigen",
    "zlib",
    "cudnn",
    "nccl",
    "magma",
    "cuda-version 12.6",
    "nvtx-c",
    "cuda-driver-dev",
    "cuda-cudart-dev",
    "cuda-cupti-dev",
    "cuda-nvrtc-dev",
    "cuda-nvtx-dev",
    "cuda-nvml-dev",
    "cuda-profiler-api",
    "cusparselt",
    "libcublas-dev",
    "libcudss-dev",
    "libcufile-dev",
    "libcufft-dev",
    "libcurand-dev",
    "libcusolver-dev",
    "libcusparse-dev"
   ],
   "run": [
    "cudnn"
   ],
   "run_constrained": [
    "pytorch-cpu ==2.5.1",
    "pytorch-gpu ==99999999",
    "pytorch 2.5.1 cpu_generic_*_12",
    "openblas * openmp_*",
    "pytorch-gpu ==2.5.1",
    "pytorch-cpu ==99999999",
    "pytorch 2.5.1 cuda126_generic_*_212"
   ]
  },
  "schema_version": 0,
  "source": {
   "patches": [
    "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
    "patches/0002-Help-find-numpy.patch",
    "patches/0003-Add-USE_SYSTEM_NVTX-option-138287.patch",
    "patches/0004-Update-sympy-version.patch",
    "patches/0006-fix-3.13-pickle-error-in-serialization.py-136034.patch",
    "patches/0007-Allow-users-to-overwrite-ld-with-environment-variabl.patch",
    "patches/0008-Allow-overriding-CUDA-related-paths.patch",
    "patches/0009-Fix-test-test_linalg.py-for-NumPy-2-136800.patch",
    "patches/0010-Fixes-NumPy-2-test-failures-in-test_torch.py-137740.patch",
    "patches/0011-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
    "patches/0012-fix-issue-142484.patch",
    "patches/0013-Fix-FindOpenBLAS.patch",
    "patches/0014-CD-Enable-Python-3.13-on-windows-138095.patch",
    "patches/0015-simplify-torch.utils.cpp_extension.include_paths-use.patch",
    "patches/0016-point-include-paths-to-PREFIX-include.patch",
    "patches/0017-Add-conda-prefix-to-inductor-include-paths.patch",
    "patches/0018-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
    "patches/0020-make-library-name-in-test_mutable_custom_op_fixed_la.patch",
    "patches/0021-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
    "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch",
    "patches/0005-Fix-duplicate-linker-script.patch"
   ],
   "sha256": "740eb5fff95e33cfe699bad43be83523f569c7cc7f9c285c2a255416443dd266",
   "url": "https://github.com/pytorch/pytorch/releases/download/v2.5.1/pytorch-v2.5.1.tar.gz"
  },
  "test": {
   "commands": [
    "test -f $PREFIX/lib/libc10.so",
    "test -f $PREFIX/lib/libshm.so",
    "test -f $PREFIX/lib/libtorch.so",
    "test -f $PREFIX/lib/libtorch_cpu.so",
    "test -f $PREFIX/lib/libtorch_global_deps.so",
    "test -f $PREFIX/share/cmake/Torch/TorchConfig.cmake",
    "cd cmake_test",
    "cmake -GNinja -DCMAKE_CXX_STANDARD=17 $CMAKE_ARGS .",
    "test -f $PREFIX/lib/libtorch_cuda_linalg.so",
    "test -f $PREFIX/lib/libc10_cuda.so",
    "test -f $PREFIX/lib/libcaffe2_nvrtc.so",
    "test -f $PREFIX/lib/libtorch_cuda.so"
   ],
   "files": [
    "cmake_test/"
   ],
   "requires": [
    "cxx_compiler_stub",
    "cmake",
    "ninja",
    "pkg-config",
    "cuda_compiler_stub",
    "cuda-nvrtc-dev"
   ]
  }
 },
 "linux_aarch64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "c_stdlib_stub",
    "cmake",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "libgomp",
    "libprotobuf",
    "make",
    "ninja",
    "protobuf",
    "python",
    "rsync"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cuda-cudart-dev",
    "cuda-cupti-dev",
    "cuda-driver-dev",
    "cuda-nvml-dev",
    "cuda-nvrtc-dev",
    "cuda-nvtx-dev",
    "cuda-profiler-api",
    "cuda-version",
    "cudnn",
    "cusparselt",
    "eigen",
    "libabseil",
    "libblas",
    "libcblas",
    "libcublas-dev",
    "libcudss-dev",
    "libcufft-dev",
    "libcufile-dev",
    "libcurand-dev",
    "libcusolver-dev",
    "libcusparse-dev",
    "libgomp",
    "liblapack",
    "libprotobuf",
    "libtorch",
    "libuv",
    "magma",
    "nccl",
    "numpy",
    "nvtx-c",
    "pip",
    "pkg-config",
    "pybind11",
    "python",
    "pyyaml",
    "requests",
    "setuptools",
    "six",
    "sleef",
    "typing_extensions",
    "zlib"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "__cuda",
    "cudnn",
    "filelock",
    "fsspec",
    "jinja2",
    "libtorch",
    "networkx",
    "nomkl",
    "pybind11",
    "python",
    "pytorch",
    "setuptools",
    "sympy",
    "triton",
    "typing_extensions"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "boto3",
    "c_compiler_stub",
    "cmake",
    "cuda-nvrtc-dev",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "expecttest",
    "hypothesis",
    "ninja",
    "pip",
    "pkg-config",
    "pydot",
    "pytest",
    "pytest-flakefinder",
    "pytest-rerunfailures",
    "pytest-xdist",
    "tabulate",
    "xmlrunner"
   ]
  }
 },
 "meta_yaml": {
  "about": {
   "description": "PyTorch is a Python package that provides two high-level features:\n  - Tensor computation (like NumPy) with strong GPU acceleration\n  - Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n",
   "dev_url": "https://github.com/pytorch/pytorch",
   "doc_url": "https://pytorch.org/docs/",
   "home": "https://pytorch.org/",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": [
    "LICENSE",
    "NOTICE",
    "third_party/CMake/Copyright.txt"
   ],
   "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
  },
  "build": {
   "detect_binary_files_with_prefix": false,
   "ignore_run_exports": [
    "python *",
    "numpy *",
    "libmagma_sparse"
   ],
   "ignore_run_exports_from": [
    "python *",
    "numpy *"
   ],
   "number": "312",
   "run_exports": [
    "libtorch"
   ],
   "skip": true,
   "string": "cuda126_mkl_h1234567_312"
  },
  "extra": {
   "feedstock-name": "pytorch-cpu",
   "recipe-maintainers": [
    "baszalmstra",
    "benjaminrwilson",
    "beckermr",
    "h-vetinari",
    "hmaarrfk",
    "jeongseok-meta",
    "mgorny",
    "sodre",
    "Tobias-Fischer"
   ]
  },
  "outputs": [
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py39_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"linux\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cpu_generic*12"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cuda126_generic_py39_h1234567_212"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "cuda-version 12.6",
      "nvtx-c",
      "magma",
      "cuda-driver-dev",
      "cuda-cudart-dev",
      "cuda-cupti-dev",
      "cuda-nvrtc-dev",
      "cuda-nvtx-dev",
      "cuda-nvml-dev",
      "cuda-profiler-api",
      "cusparselt",
      "libcublas-dev",
      "libcudss-dev",
      "libcufile-dev",
      "libcufft-dev",
      "libcurand-dev",
      "libcusolver-dev",
      "libcusparse-dev",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "cudnn",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "__cuda",
      "libtorch 2.5.1",
      "setuptools",
      "triton 3.1.0"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.5.1",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
      "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
      "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"12.6\"",
      "export MATRIX_GPU_ARCH_TYPE=\"cuda\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"linux\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda126_generic_h1234567_212",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cuda*_generic*212"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py39_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "libgomp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"linux\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cpu_mkl*112"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cuda126_mkl_py39_h1234567_312"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "cuda-version 12.6",
      "nvtx-c",
      "magma",
      "cuda-driver-dev",
      "cuda-cudart-dev",
      "cuda-cupti-dev",
      "cuda-nvrtc-dev",
      "cuda-nvtx-dev",
      "cuda-nvml-dev",
      "cuda-profiler-api",
      "cusparselt",
      "libcublas-dev",
      "libcudss-dev",
      "libcufile-dev",
      "libcufft-dev",
      "libcurand-dev",
      "libcusolver-dev",
      "libcusparse-dev",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "libgomp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "libblas * *mkl",
      "cudnn",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "__cuda",
      "libtorch 2.5.1",
      "setuptools",
      "triton 3.1.0"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.5.1",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
      "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
      "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"12.6\"",
      "export MATRIX_GPU_ARCH_TYPE=\"cuda\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"linux\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda126_mkl_h1234567_312",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cuda*_mkl*312"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py39_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"linux\"",
      "export OMP_NUM_THREADS=4",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cpu_generic*12"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cuda126_generic_py39_h1234567_212"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "libgomp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "make"
     ],
     "host": [
      "cudnn",
      "nccl",
      "cuda-version 12.6",
      "nvtx-c",
      "magma",
      "cuda-driver-dev",
      "cuda-cudart-dev",
      "cuda-cupti-dev",
      "cuda-nvrtc-dev",
      "cuda-nvtx-dev",
      "cuda-nvml-dev",
      "cuda-profiler-api",
      "cusparselt",
      "libcublas-dev",
      "libcudss-dev",
      "libcufile-dev",
      "libcufft-dev",
      "libcurand-dev",
      "libcusolver-dev",
      "libcusparse-dev",
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "libgomp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "cudnn",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "__cuda",
      "libtorch 2.5.1",
      "setuptools",
      "triton 3.1.0"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.5.1",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"linux\"",
      "export OMP_NUM_THREADS=4",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda126_generic_h1234567_212",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cuda*_generic*212"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py310_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py310_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py311_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py311_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py312_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py312_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py39_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py39_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py313_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py313_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py310_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_py310_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py311_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_py311_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py312_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_py312_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py39_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_py39_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py313_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_py313_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py310_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-arm64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py310_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py311_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-arm64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py311_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py312_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-arm64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py312_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py39_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-arm64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py39_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py313_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-arm64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py313_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py39_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "intel-openmp <2025",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "sccache"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools <=72.1.0",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "intel-openmp <2025",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "intel-openmp <2025",
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "bld.bat",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "if not exist %LIBRARY_BIN%\\torch_python.dll exit 1",
      "if not exist %LIBRARY_LIB%\\torch_python.lib exit 1",
      "set MATRIX_GPU_ARCH_VERSION=\"none\"",
      "set MATRIX_GPU_ARCH_TYPE=\"none\"",
      "set MATRIX_CHANNEL=\"defaults\"",
      "set MATRIX_STABLE_VERSION=2.5.1",
      "set MATRIX_PACKAGE_TYPE=\"conda\"",
      "set TARGET_OS=\"windows\"",
      "set OMP_NUM_THREADS=4",
      "python -m pytest -v -s test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "if exist %SP_DIR%\\functorch\\__pycache__\\__init__.cpython-313.pyc exit 1"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cpu_mkl*112"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cuda126_mkl_py39_h1234567_312"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "intel-openmp <2025",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "sccache"
     ],
     "host": [
      "cudnn",
      "cuda-version 12.6",
      "nvtx-c",
      "magma",
      "cuda-cudart-dev",
      "cuda-cupti-dev",
      "cuda-nvrtc-dev",
      "cuda-nvtx-dev",
      "cuda-nvml-dev",
      "cuda-profiler-api",
      "cusparselt",
      "libcublas-dev",
      "libcudss-dev",
      "libcufft-dev",
      "libcurand-dev",
      "libcusolver-dev",
      "libcusparse-dev",
      "python",
      "numpy",
      "pip",
      "setuptools <=72.1.0",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "intel-openmp <2025",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "intel-openmp <2025",
      "libblas * *mkl",
      "cudnn",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "__cuda",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.5.1",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "bld.bat",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "if not exist %LIBRARY_BIN%\\torch_python.dll exit 1",
      "if not exist %LIBRARY_LIB%\\torch_python.lib exit 1",
      "set MATRIX_GPU_ARCH_VERSION=\"12.6\"",
      "set MATRIX_GPU_ARCH_TYPE=\"cuda\"",
      "set MATRIX_CHANNEL=\"defaults\"",
      "set MATRIX_STABLE_VERSION=2.5.1",
      "set MATRIX_PACKAGE_TYPE=\"conda\"",
      "set TARGET_OS=\"windows\"",
      "set OMP_NUM_THREADS=4",
      "python -m pytest -v -s test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "if exist %SP_DIR%\\functorch\\__pycache__\\__init__.cpython-313.pyc exit 1"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda126_mkl_h1234567_312",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cuda*_mkl*312"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   }
  ],
  "package": {
   "name": "libtorch",
   "version": "2.5.1"
  },
  "requirements": {
   "build": [
    "c_stdlib_stub",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "libgomp",
    "cmake",
    "ninja",
    "libprotobuf",
    "protobuf",
    "make",
    "rsync",
    "cuda_compiler_stub",
    "llvm-openmp",
    "intel-openmp <2025",
    "libuv",
    "sccache"
   ],
   "host": [
    "python 3.12",
    "numpy *",
    "pip",
    "setuptools",
    "pyyaml",
    "requests",
    "six",
    "libblas",
    "libcblas",
    "liblapack",
    "libgomp",
    "libabseil",
    "libprotobuf",
    "sleef",
    "libuv",
    "pkg-config",
    "typing_extensions",
    "pybind11",
    "eigen",
    "zlib",
    "cudnn",
    "nccl",
    "magma",
    "cuda-version 12.6",
    "nvtx-c",
    "cuda-driver-dev",
    "cuda-cudart-dev",
    "cuda-cupti-dev",
    "cuda-nvrtc-dev",
    "cuda-nvtx-dev",
    "cuda-nvml-dev",
    "cuda-profiler-api",
    "cusparselt",
    "libcublas-dev",
    "libcudss-dev",
    "libcufile-dev",
    "libcufft-dev",
    "libcurand-dev",
    "libcusolver-dev",
    "libcusparse-dev",
    "mkl-devel <2025",
    "libcblas * *_mkl",
    "python",
    "numpy",
    "llvm-openmp",
    "setuptools <=72.1.0",
    "intel-openmp <2025"
   ],
   "run": [
    "cudnn",
    "libblas * *mkl",
    "intel-openmp <2025"
   ],
   "run_constrained": [
    "pytorch-cpu ==2.5.1",
    "pytorch-gpu ==99999999",
    "pytorch 2.5.1 cpu_generic_*_12",
    "openblas * openmp_*",
    "pytorch-gpu ==2.5.1",
    "pytorch-cpu ==99999999",
    "pytorch 2.5.1 cuda126_generic_*_212",
    "pytorch 2.5.1 cpu_mkl_*_112",
    "pytorch 2.5.1 cuda126_mkl_*_312"
   ]
  },
  "schema_version": 0,
  "source": {
   "patches": [
    "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
    "patches/0002-Help-find-numpy.patch",
    "patches/0003-Add-USE_SYSTEM_NVTX-option-138287.patch",
    "patches/0004-Update-sympy-version.patch",
    "patches/0006-fix-3.13-pickle-error-in-serialization.py-136034.patch",
    "patches/0007-Allow-users-to-overwrite-ld-with-environment-variabl.patch",
    "patches/0008-Allow-overriding-CUDA-related-paths.patch",
    "patches/0009-Fix-test-test_linalg.py-for-NumPy-2-136800.patch",
    "patches/0010-Fixes-NumPy-2-test-failures-in-test_torch.py-137740.patch",
    "patches/0011-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
    "patches/0012-fix-issue-142484.patch",
    "patches/0013-Fix-FindOpenBLAS.patch",
    "patches/0014-CD-Enable-Python-3.13-on-windows-138095.patch",
    "patches/0015-simplify-torch.utils.cpp_extension.include_paths-use.patch",
    "patches/0016-point-include-paths-to-PREFIX-include.patch",
    "patches/0017-Add-conda-prefix-to-inductor-include-paths.patch",
    "patches/0018-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
    "patches/0020-make-library-name-in-test_mutable_custom_op_fixed_la.patch",
    "patches/0021-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
    "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch",
    "patches/0005-Fix-duplicate-linker-script.patch",
    "patches/0019-remove-DESTINATION-lib-from-CMake-install-TARGETS-di.patch",
    "patches_submodules/fbgemm/0001-remove-DESTINATION-lib-from-CMake-install-directives.patch"
   ],
   "sha256": "740eb5fff95e33cfe699bad43be83523f569c7cc7f9c285c2a255416443dd266",
   "url": "https://github.com/pytorch/pytorch/releases/download/v2.5.1/pytorch-v2.5.1.tar.gz"
  },
  "test": {
   "commands": [
    "test -f $PREFIX/lib/libc10.so",
    "test -f $PREFIX/lib/libshm.so",
    "test -f $PREFIX/lib/libtorch.so",
    "test -f $PREFIX/lib/libtorch_cpu.so",
    "test -f $PREFIX/lib/libtorch_global_deps.so",
    "test -f $PREFIX/share/cmake/Torch/TorchConfig.cmake",
    "cd cmake_test",
    "cmake -GNinja -DCMAKE_CXX_STANDARD=17 $CMAKE_ARGS .",
    "test -f $PREFIX/lib/libtorch_cuda_linalg.so",
    "test -f $PREFIX/lib/libc10_cuda.so",
    "test -f $PREFIX/lib/libcaffe2_nvrtc.so",
    "test -f $PREFIX/lib/libtorch_cuda.so",
    "test -f $PREFIX/lib/libc10.dylib",
    "test -f $PREFIX/lib/libshm.dylib",
    "test -f $PREFIX/lib/libtorch.dylib",
    "test -f $PREFIX/lib/libtorch_cpu.dylib",
    "test -f $PREFIX/lib/libtorch_global_deps.dylib",
    "if not exist %LIBRARY_BIN%\\c10.dll exit 1",
    "if not exist %LIBRARY_LIB%\\c10.lib exit 1",
    "if not exist %LIBRARY_BIN%\\shm.dll exit 1",
    "if not exist %LIBRARY_LIB%\\shm.lib exit 1",
    "if not exist %LIBRARY_BIN%\\torch.dll exit 1",
    "if not exist %LIBRARY_LIB%\\torch.lib exit 1",
    "if not exist %LIBRARY_BIN%\\torch_cpu.dll exit 1",
    "if not exist %LIBRARY_LIB%\\torch_cpu.lib exit 1",
    "if not exist %LIBRARY_BIN%\\torch_global_deps.dll exit 1",
    "if not exist %LIBRARY_BIN%\\asmjit.dll exit 1",
    "if not exist %LIBRARY_LIB%\\asmjit.lib exit 1",
    "if not exist %LIBRARY_BIN%\\fbgemm.dll exit 1",
    "if not exist %LIBRARY_LIB%\\fbgemm.lib exit 1",
    "if not exist %LIBRARY_PREFIX%\\share\\cmake\\Torch\\TorchConfig.cmake exit 1",
    "cmake -GNinja -DCMAKE_CXX_STANDARD=17 %CMAKE_ARGS% .",
    "if not exist %LIBRARY_BIN%\\c10_cuda.dll exit 1",
    "if not exist %LIBRARY_LIB%\\c10_cuda.lib exit 1",
    "if not exist %LIBRARY_BIN%\\caffe2_nvrtc.dll exit 1",
    "if not exist %LIBRARY_LIB%\\caffe2_nvrtc.lib exit 1",
    "if not exist %LIBRARY_BIN%\\torch_cuda.dll exit 1",
    "if not exist %LIBRARY_LIB%\\torch_cuda.lib exit 1"
   ],
   "files": [
    "cmake_test/"
   ],
   "requires": [
    "cxx_compiler_stub",
    "cmake",
    "ninja",
    "pkg-config",
    "cuda_compiler_stub",
    "cuda-nvrtc-dev"
   ]
  }
 },
 "name": "libtorch",
 "osx_64_meta_yaml": {
  "about": {
   "description": "PyTorch is a Python package that provides two high-level features:\n  - Tensor computation (like NumPy) with strong GPU acceleration\n  - Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n",
   "dev_url": "https://github.com/pytorch/pytorch",
   "doc_url": "https://pytorch.org/docs/",
   "home": "https://pytorch.org/",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": [
    "LICENSE",
    "NOTICE",
    "third_party/CMake/Copyright.txt"
   ],
   "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
  },
  "build": {
   "detect_binary_files_with_prefix": false,
   "ignore_run_exports": [
    "libmagma_sparse"
   ],
   "ignore_run_exports_from": null,
   "number": "112",
   "run_exports": [
    "libtorch"
   ],
   "skip": true,
   "string": "cpu_mkl_h1234567_112"
  },
  "extra": {
   "feedstock-name": "pytorch-cpu",
   "recipe-maintainers": [
    "baszalmstra",
    "benjaminrwilson",
    "beckermr",
    "h-vetinari",
    "hmaarrfk",
    "jeongseok-meta",
    "mgorny",
    "sodre",
    "Tobias-Fischer"
   ]
  },
  "outputs": [
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py310_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py310_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py311_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py311_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py312_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py312_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py39_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py39_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py313_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py313_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py310_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_py310_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py311_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_py311_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py312_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_py312_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py39_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_py39_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py313_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-x86_64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_py313_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   }
  ],
  "package": {
   "name": "libtorch",
   "version": "2.5.1"
  },
  "requirements": {
   "build": [
    "c_stdlib_stub",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "llvm-openmp",
    "cmake",
    "ninja",
    "libprotobuf",
    "protobuf",
    "rsync"
   ],
   "host": [
    "python",
    "numpy",
    "pip",
    "setuptools",
    "pyyaml",
    "requests",
    "six",
    "libblas",
    "libcblas",
    "liblapack",
    "llvm-openmp",
    "libabseil",
    "libprotobuf",
    "sleef",
    "libuv",
    "pkg-config",
    "typing_extensions",
    "pybind11",
    "eigen",
    "zlib",
    "mkl-devel <2025",
    "libcblas * *_mkl"
   ],
   "run": [
    "libblas * *mkl"
   ],
   "run_constrained": [
    "pytorch-cpu ==2.5.1",
    "pytorch-gpu ==99999999",
    "pytorch 2.5.1 cpu_generic_*_12",
    "openblas * openmp_*",
    "pytorch 2.5.1 cpu_mkl_*_112"
   ]
  },
  "schema_version": 0,
  "source": {
   "patches": [
    "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
    "patches/0002-Help-find-numpy.patch",
    "patches/0003-Add-USE_SYSTEM_NVTX-option-138287.patch",
    "patches/0004-Update-sympy-version.patch",
    "patches/0006-fix-3.13-pickle-error-in-serialization.py-136034.patch",
    "patches/0007-Allow-users-to-overwrite-ld-with-environment-variabl.patch",
    "patches/0008-Allow-overriding-CUDA-related-paths.patch",
    "patches/0009-Fix-test-test_linalg.py-for-NumPy-2-136800.patch",
    "patches/0010-Fixes-NumPy-2-test-failures-in-test_torch.py-137740.patch",
    "patches/0011-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
    "patches/0012-fix-issue-142484.patch",
    "patches/0013-Fix-FindOpenBLAS.patch",
    "patches/0014-CD-Enable-Python-3.13-on-windows-138095.patch",
    "patches/0015-simplify-torch.utils.cpp_extension.include_paths-use.patch",
    "patches/0016-point-include-paths-to-PREFIX-include.patch",
    "patches/0017-Add-conda-prefix-to-inductor-include-paths.patch",
    "patches/0018-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
    "patches/0020-make-library-name-in-test_mutable_custom_op_fixed_la.patch",
    "patches/0021-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
    "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
   ],
   "sha256": "740eb5fff95e33cfe699bad43be83523f569c7cc7f9c285c2a255416443dd266",
   "url": "https://github.com/pytorch/pytorch/releases/download/v2.5.1/pytorch-v2.5.1.tar.gz"
  },
  "test": {
   "commands": [
    "test -f $PREFIX/lib/libc10.dylib",
    "test -f $PREFIX/lib/libshm.dylib",
    "test -f $PREFIX/lib/libtorch.dylib",
    "test -f $PREFIX/lib/libtorch_cpu.dylib",
    "test -f $PREFIX/lib/libtorch_global_deps.dylib",
    "cd cmake_test",
    "cmake -GNinja -DCMAKE_CXX_STANDARD=17 $CMAKE_ARGS ."
   ],
   "files": [
    "cmake_test/"
   ],
   "requires": [
    "cxx_compiler_stub",
    "cmake",
    "ninja",
    "pkg-config"
   ]
  }
 },
 "osx_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "c_stdlib_stub",
    "cmake",
    "cxx_compiler_stub",
    "libprotobuf",
    "llvm-openmp",
    "ninja",
    "protobuf",
    "python",
    "rsync"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "eigen",
    "libabseil",
    "libblas",
    "libcblas",
    "liblapack",
    "libprotobuf",
    "libtorch",
    "libuv",
    "llvm-openmp",
    "mkl-devel",
    "numpy",
    "pip",
    "pkg-config",
    "pybind11",
    "python",
    "pyyaml",
    "requests",
    "setuptools",
    "six",
    "sleef",
    "typing_extensions",
    "zlib"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "filelock",
    "fsspec",
    "jinja2",
    "libblas",
    "libtorch",
    "llvm-openmp",
    "networkx",
    "nomkl",
    "pybind11",
    "python",
    "pytorch",
    "setuptools",
    "sympy",
    "typing_extensions"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "boto3",
    "c_compiler_stub",
    "cmake",
    "cxx_compiler_stub",
    "expecttest",
    "hypothesis",
    "ninja",
    "pip",
    "pkg-config",
    "pydot",
    "pytest",
    "pytest-flakefinder",
    "pytest-rerunfailures",
    "pytest-xdist",
    "tabulate",
    "xmlrunner"
   ]
  }
 },
 "osx_arm64_meta_yaml": {
  "about": {
   "description": "PyTorch is a Python package that provides two high-level features:\n  - Tensor computation (like NumPy) with strong GPU acceleration\n  - Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n",
   "dev_url": "https://github.com/pytorch/pytorch",
   "doc_url": "https://pytorch.org/docs/",
   "home": "https://pytorch.org/",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": [
    "LICENSE",
    "NOTICE",
    "third_party/CMake/Copyright.txt"
   ],
   "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
  },
  "build": {
   "detect_binary_files_with_prefix": false,
   "ignore_run_exports": [
    "libmagma_sparse"
   ],
   "ignore_run_exports_from": null,
   "number": "12",
   "run_exports": [
    "libtorch"
   ],
   "skip": true,
   "string": "cpu_generic_h1234567_12"
  },
  "extra": {
   "feedstock-name": "pytorch-cpu",
   "recipe-maintainers": [
    "baszalmstra",
    "benjaminrwilson",
    "beckermr",
    "h-vetinari",
    "hmaarrfk",
    "jeongseok-meta",
    "mgorny",
    "sodre",
    "Tobias-Fischer"
   ]
  },
  "outputs": [
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py310_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-arm64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py310_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py311_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-arm64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py311_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py312_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-arm64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py312_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py39_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-arm64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py39_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_generic_py313_h1234567_12"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "llvm-openmp",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools",
      "pyyaml",
      "requests",
      "six",
      "libcblas",
      "liblapack",
      "llvm-openmp",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "pkg-config",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "llvm-openmp",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "nomkl",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "build.sh",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "python -c \"import torch; assert torch.distributed.is_available()\"",
      "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
      "export MATRIX_GPU_ARCH_VERSION=\"none\"",
      "export MATRIX_GPU_ARCH_TYPE=\"none\"",
      "export MATRIX_CHANNEL=\"defaults\"",
      "export MATRIX_STABLE_VERSION=\"2.5.1\"",
      "export MATRIX_PACKAGE_TYPE=\"conda\"",
      "export TARGET_OS=\"macos-arm64\"",
      "export OMP_NUM_THREADS=4",
      "python -m pytest -n 2 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_generic_py313_h1234567_12",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   }
  ],
  "package": {
   "name": "libtorch",
   "version": "2.5.1"
  },
  "requirements": {
   "build": [
    "c_stdlib_stub",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "llvm-openmp",
    "cmake",
    "ninja",
    "libprotobuf",
    "protobuf",
    "rsync"
   ],
   "host": [
    "python",
    "numpy",
    "pip",
    "setuptools",
    "pyyaml",
    "requests",
    "six",
    "libblas",
    "libcblas",
    "liblapack",
    "llvm-openmp",
    "libabseil",
    "libprotobuf",
    "sleef",
    "libuv",
    "pkg-config",
    "typing_extensions",
    "pybind11",
    "eigen",
    "zlib"
   ],
   "run": [],
   "run_constrained": [
    "pytorch-cpu ==2.5.1",
    "pytorch-gpu ==99999999",
    "pytorch 2.5.1 cpu_generic_*_12",
    "openblas * openmp_*"
   ]
  },
  "schema_version": 0,
  "source": {
   "patches": [
    "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
    "patches/0002-Help-find-numpy.patch",
    "patches/0003-Add-USE_SYSTEM_NVTX-option-138287.patch",
    "patches/0004-Update-sympy-version.patch",
    "patches/0006-fix-3.13-pickle-error-in-serialization.py-136034.patch",
    "patches/0007-Allow-users-to-overwrite-ld-with-environment-variabl.patch",
    "patches/0008-Allow-overriding-CUDA-related-paths.patch",
    "patches/0009-Fix-test-test_linalg.py-for-NumPy-2-136800.patch",
    "patches/0010-Fixes-NumPy-2-test-failures-in-test_torch.py-137740.patch",
    "patches/0011-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
    "patches/0012-fix-issue-142484.patch",
    "patches/0013-Fix-FindOpenBLAS.patch",
    "patches/0014-CD-Enable-Python-3.13-on-windows-138095.patch",
    "patches/0015-simplify-torch.utils.cpp_extension.include_paths-use.patch",
    "patches/0016-point-include-paths-to-PREFIX-include.patch",
    "patches/0017-Add-conda-prefix-to-inductor-include-paths.patch",
    "patches/0018-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
    "patches/0020-make-library-name-in-test_mutable_custom_op_fixed_la.patch",
    "patches/0021-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
    "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
   ],
   "sha256": "740eb5fff95e33cfe699bad43be83523f569c7cc7f9c285c2a255416443dd266",
   "url": "https://github.com/pytorch/pytorch/releases/download/v2.5.1/pytorch-v2.5.1.tar.gz"
  },
  "test": {
   "commands": [
    "test -f $PREFIX/lib/libc10.dylib",
    "test -f $PREFIX/lib/libshm.dylib",
    "test -f $PREFIX/lib/libtorch.dylib",
    "test -f $PREFIX/lib/libtorch_cpu.dylib",
    "test -f $PREFIX/lib/libtorch_global_deps.dylib",
    "cd cmake_test",
    "cmake -GNinja -DCMAKE_CXX_STANDARD=17 $CMAKE_ARGS ."
   ],
   "files": [
    "cmake_test/"
   ],
   "requires": [
    "cxx_compiler_stub",
    "cmake",
    "ninja",
    "pkg-config"
   ]
  }
 },
 "osx_arm64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "c_stdlib_stub",
    "cmake",
    "cxx_compiler_stub",
    "libprotobuf",
    "llvm-openmp",
    "ninja",
    "protobuf",
    "python",
    "rsync"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "eigen",
    "libabseil",
    "libblas",
    "libcblas",
    "liblapack",
    "libprotobuf",
    "libtorch",
    "libuv",
    "llvm-openmp",
    "numpy",
    "pip",
    "pkg-config",
    "pybind11",
    "python",
    "pyyaml",
    "requests",
    "setuptools",
    "six",
    "sleef",
    "typing_extensions",
    "zlib"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "filelock",
    "fsspec",
    "jinja2",
    "libtorch",
    "llvm-openmp",
    "networkx",
    "nomkl",
    "pybind11",
    "python",
    "pytorch",
    "setuptools",
    "sympy",
    "typing_extensions"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "boto3",
    "c_compiler_stub",
    "cmake",
    "cxx_compiler_stub",
    "expecttest",
    "hypothesis",
    "ninja",
    "pip",
    "pkg-config",
    "pydot",
    "pytest",
    "pytest-flakefinder",
    "pytest-rerunfailures",
    "pytest-xdist",
    "tabulate",
    "xmlrunner"
   ]
  }
 },
 "outputs_names": {
  "__set__": true,
  "elements": [
   "libtorch",
   "pytorch",
   "pytorch-gpu"
  ]
 },
 "parsing_error": false,
 "platforms": [
  "linux_64",
  "linux_aarch64",
  "osx_64",
  "osx_arm64",
  "win_64"
 ],
 "pr_info": {
  "__lazy_json__": "pr_info/pytorch-cpu.json"
 },
 "raw_meta_yaml": "# if you wish to build release candidate number X, append the version string with \".rcX\"\n{% set version = \"2.5.1\" %}\n{% set build = 12 %}\n\n# Use a higher build number for the CUDA variant, to ensure that it's\n# preferred by conda's solver, and it's preferentially\n# installed where the platform supports it.\n{% if cuda_compiler_version != \"None\" %}\n{% set build = build + 200 %}\n{% endif %}\n\n{% if blas_impl == \"mkl\" %}\n{% set build = build + 100 %}\n{% endif %}\n\n# see .ci/docker/ci_commit_pins/triton.txt\n# pytorch and triton are released in tandem, see notes in their release process\n# https://github.com/pytorch/pytorch/blob/main/RELEASE.md#triton-dependency-for-the-release\n{% set triton = \"3.1.0\" %}\n\n# TODO Temporary pin, remove me\n{% set mkl = \"<2025\" %}\n\npackage:\n  name: libtorch\n  version: {{ version }}\n\nsource:\n{% if \"rc\" in version %}\n  git_url: https://github.com/pytorch/pytorch.git\n  git_rev: v{{ version.replace(\".rc\", \"-rc\") }}\n{% else %}\n  # The \"pytorch-v\" tarballs contain submodules; the \"pytorch-\" ones don't.\n  url: https://github.com/pytorch/pytorch/releases/download/v{{ version }}/pytorch-v{{ version }}.tar.gz\n  sha256: 740eb5fff95e33cfe699bad43be83523f569c7cc7f9c285c2a255416443dd266\n{% endif %}\n  patches:\n    - patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch\n    # https://github.com/pytorch/pytorch/pull/137084\n    - patches/0002-Help-find-numpy.patch\n    # https://github.com/pytorch/pytorch/pull/138287\n    - patches/0003-Add-USE_SYSTEM_NVTX-option-138287.patch\n    # sympy 1.13.2 was reported to result in test failures on Windows and mac\n    # https://github.com/pytorch/pytorch/pull/133235\n    - patches/0004-Update-sympy-version.patch\n    - patches/0005-Fix-duplicate-linker-script.patch  # [cuda_compiler_version != \"None\" and aarch64]\n    # https://github.com/pytorch/pytorch/pull/136034\n    - patches/0006-fix-3.13-pickle-error-in-serialization.py-136034.patch\n    # https://github.com/pytorch/pytorch/pull/137331\n    - patches/0007-Allow-users-to-overwrite-ld-with-environment-variabl.patch\n    # conda-specific patch, lets us override CUDA paths\n    - patches/0008-Allow-overriding-CUDA-related-paths.patch\n    # NumPy 2 fixes:\n    # https://github.com/pytorch/pytorch/pull/136800\n    - patches/0009-Fix-test-test_linalg.py-for-NumPy-2-136800.patch\n    # https://github.com/pytorch/pytorch/pull/137740\n    - patches/0010-Fixes-NumPy-2-test-failures-in-test_torch.py-137740.patch\n    # fix BLAS calling convention for openblas\n    - patches/0011-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch\n    # fix mkl-2024 issue\n    # https://github.com/pytorch/pytorch/pull/143894\n    - patches/0012-fix-issue-142484.patch\n    - patches/0013-Fix-FindOpenBLAS.patch\n    # backport https://github.com/pytorch/pytorch/pull/138095\n    - patches/0014-CD-Enable-Python-3.13-on-windows-138095.patch\n    # backport https://github.com/pytorch/pytorch/pull/145480\n    - patches/0015-simplify-torch.utils.cpp_extension.include_paths-use.patch\n    # point to headers that are now living in $PREFIX/include instead of $SP_DIR/torch/include\n    - patches/0016-point-include-paths-to-PREFIX-include.patch\n    - patches/0017-Add-conda-prefix-to-inductor-include-paths.patch\n    - patches/0018-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch\n    - patches/0019-remove-DESTINATION-lib-from-CMake-install-TARGETS-di.patch                       # [win]\n    - patches/0020-make-library-name-in-test_mutable_custom_op_fixed_la.patch\n    - patches/0021-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch\n    - patches_submodules/fbgemm/0001-remove-DESTINATION-lib-from-CMake-install-directives.patch     # [win]\n    - patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch\n\nbuild:\n  number: {{ build }}\n  # cuda 11.8 was dropped due to maintenance effort, see discussion in #177\n  skip: true  # [cuda_compiler_version == \"11.8\"]\n  # temporary skip to avoid wasting resources while unbreak CUDA builds\n  skip: true  # [cuda_compiler_version == \"None\"]\n  # This logic allows two rc variants to be defined in the conda_build_config, but only one to actually be built.\n  # We want to be able to define two variants in the cbc so we can assign different labels to each in the upload channel\n  # (by zipping is_rc with channel_targets). This prevents rc builds being used unless specifically requested.\n{% if \"rc\" in version %}\n  skip: true  # [not is_rc]\n{% else %}\n  skip: true  # [is_rc]\n{% endif %}\n  string: cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != \"None\"]\n  string: cpu_{{ blas_impl }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                 # [cuda_compiler_version == \"None\"]\n  detect_binary_files_with_prefix: false\n  run_exports:\n    - {{ pin_subpackage('libtorch', max_pin='x.x') }}\n  ignore_run_exports_from:\n    - python *                               # [megabuild]\n    - numpy *                                # [megabuild]\n    - cross-python_{{ target_platform }}     # [megabuild and build_platform != target_platform]\n  ignore_run_exports:\n    - python *                               # [megabuild]\n    - numpy *                                # [megabuild]\n    - libmagma_sparse\n\nrequirements:\n  # Keep this list synchronized (except for python*, numpy*) in outputs\n  # We use python to build libtorch as well because it is easier\n  build:\n    # When you change 3.12 here, change it in build.sh/bld.bat as well\n    - python 3.12                            # [megabuild and build_platform != target_platform]\n    - python                                 # [not megabuild and build_platform != target_platform]\n    - cross-python_{{ target_platform }}     # [build_platform != target_platform]\n    - numpy  *                               # [megabuild and build_platform != target_platform]\n    - numpy                                  # [not megabuild and build_platform != target_platform]\n    - {{ stdlib('c') }}\n    - {{ compiler('c') }}\n    - {{ compiler('cxx') }}\n    - {{ compiler('cuda') }}                 # [cuda_compiler_version != \"None\"]\n    - libgomp        # [linux]\n    - llvm-openmp    # [osx]\n    - intel-openmp {{ mkl }}  # [win]\n    - libuv          # [win]\n    - cmake\n    - ninja\n    # Keep libprotobuf here so that a compatibile version\n    # of protobuf is installed between build and host\n    - libprotobuf\n    - protobuf\n    - make      # [linux]\n    - sccache   # [win]\n    - rsync     # [unix]\n  host:\n    # GPU requirements\n    - cudnn                           # [cuda_compiler_version != \"None\"]\n    - nccl                            # [cuda_compiler_version != \"None\" and linux]\n    - magma                           # [cuda_compiler_version != \"None\"]\n    - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version != \"None\"]\n    - nvtx-c                          # [cuda_compiler_version != \"None\"]\n    {% if cuda_compiler_version != \"None\" %}\n    - cuda-driver-dev                 # [linux]\n    - cuda-cudart-dev\n    - cuda-cupti-dev\n    - cuda-nvrtc-dev\n    - cuda-nvtx-dev\n    - cuda-nvml-dev\n    - cuda-profiler-api\n    - cusparselt\n    - libcublas-dev\n    - libcudss-dev\n    - libcufile-dev  # [linux]\n    - libcufft-dev\n    - libcurand-dev\n    - libcusolver-dev\n    - libcusparse-dev\n    {% endif %}\n    # other requirements\n    - python 3.12  # [megabuild]\n    - python       # [not megabuild]\n    - numpy *      # [megabuild]\n    - numpy        # [not megabuild]\n    - pip\n    # see https://github.com/pytorch/pytorch/issues/136541\n    - setuptools <=72.1.0  # [win]\n    - setuptools  # [not win]\n    - pyyaml\n    - requests\n    - six\n    - mkl-devel {{ mkl }}   # [blas_impl == \"mkl\"]\n    - libcblas * *_mkl      # [blas_impl == \"mkl\"]\n    - libblas               # [blas_impl != \"mkl\"]\n    - libcblas              # [blas_impl != \"mkl\"]\n    - liblapack             # [blas_impl != \"mkl\"]\n    - libgomp   # [linux]\n    - llvm-openmp    # [osx]\n    - intel-openmp {{ mkl }}  # [win]\n    - libabseil\n    - libprotobuf\n    - sleef\n    - libuv\n    - pkg-config  # [unix]\n    - typing_extensions\n    - pybind11\n    - eigen\n    - zlib\n  run:\n    # GPU requirements without run_exports\n    - {{ pin_compatible('cudnn') }}                       # [cuda_compiler_version != \"None\"]\n    - intel-openmp {{ mkl }}  # [win]\n    - libblas * *{{ blas_impl }}  # [blas_impl == \"mkl\"]\n  run_constrained:\n    # These constraints ensure conflict between pytorch and\n    # pytorch-cpu 1.1 which we built before conda-forge had GPU infrastructure\n    # built into place.\n    # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/65\n    - pytorch-cpu =={{ version }}  # [cuda_compiler_version == \"None\"]\n    - pytorch-gpu ==99999999       # [cuda_compiler_version == \"None\"]\n    - pytorch-gpu =={{ version }}  # [cuda_compiler_version != \"None\"]\n    - pytorch-cpu ==99999999       # [cuda_compiler_version != \"None\"]\n    - pytorch {{ version }} cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_*_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != \"None\"]\n    - pytorch {{ version }} cpu_{{ blas_impl }}_*_{{ PKG_BUILDNUM }}                                                 # [cuda_compiler_version == \"None\"]\n    # if using OpenBLAS, ensure that a version compatible with OpenMP is used\n    # otherwise, we get the following warnings:\n    # OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n    - openblas * openmp_*          # [unix and blas_impl != \"mkl\"]\n\n# these tests are for the libtorch output below, but due to\n# a particularity of conda-build, that output is defined in\n# the global build stage, including tests\ntest:\n  requires:\n    # cmake needs a compiler to run package detection, see\n    # https://discourse.cmake.org/t/questions-about-find-package-cli-msvc/6194\n    - {{ compiler('cxx') }}\n    # for CMake config to find cuda & nvrtc\n    - {{ compiler('cuda') }}    # [cuda_compiler_version != \"None\"]\n    - cuda-nvrtc-dev            # [cuda_compiler_version != \"None\"]\n    - cmake\n    - ninja\n    - pkg-config\n  files:\n    - cmake_test/\n  commands:\n    # libraries; peculiar formatting to avoid linter false positives about selectors\n    {% set torch_libs = [\n        \"c10\", \"shm\", \"torch\", \"torch_cpu\", \"torch_global_deps\"\n    ] + (cuda_compiler_version != \"None\" and target_platform.startswith(\"linux\")) * [\n        \"torch_cuda_linalg\"\n    ] + (cuda_compiler_version != \"None\") * [\n        \"c10_cuda\", \"caffe2_nvrtc\", \"torch_cuda\"\n    ] + target_platform.startswith(\"win\") * [\n        \"asmjit\", \"fbgemm\"\n    ]\n    %}\n    {% for each_lib in torch_libs %}\n    - test -f $PREFIX/lib/lib{{ each_lib }}.so              # [linux]\n    - test -f $PREFIX/lib/lib{{ each_lib }}.dylib           # [osx]\n    - if not exist %LIBRARY_BIN%\\{{ each_lib }}.dll exit 1  # [win]\n    {% if each_lib != \"torch_global_deps\" %}\n    - if not exist %LIBRARY_LIB%\\{{ each_lib }}.lib exit 1  # [win]\n    {% endif %}\n    {% endfor %}\n\n    # CMake files in share\n    - test -f $PREFIX/share/cmake/Torch/TorchConfig.cmake                       # [linux]\n    - if not exist %LIBRARY_PREFIX%\\share\\cmake\\Torch\\TorchConfig.cmake exit 1  # [win]\n\n    # test integrity of CMake metadata\n    - cd cmake_test\n    - cmake -GNinja -DCMAKE_CXX_STANDARD=17 $CMAKE_ARGS .   # [unix]\n    - cmake -GNinja -DCMAKE_CXX_STANDARD=17 %CMAKE_ARGS% .  # [win]\n\noutputs:\n  - name: libtorch\n  - name: pytorch\n    script: build.sh    # [unix]\n    script: bld.bat     # [win]\n    build:\n      string: cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_py{{ CONDA_PY }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != \"None\"]\n      string: cpu_{{ blas_impl }}_py{{ CONDA_PY }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                 # [cuda_compiler_version == \"None\"]\n      detect_binary_files_with_prefix: false\n      run_exports:\n        - {{ pin_subpackage('pytorch', max_pin='x.x') }}\n        - {{ pin_subpackage('libtorch', max_pin='x.x') }}\n      ignore_run_exports:\n        - libmagma_sparse\n    requirements:\n      build:\n        - python\n        - cross-python_{{ target_platform }}     # [build_platform != target_platform]\n        - numpy                                  # [build_platform != target_platform]\n        - {{ stdlib('c') }}\n        - {{ compiler('c') }}\n        - {{ compiler('cxx') }}\n        - {{ compiler('cuda') }}                 # [cuda_compiler_version != \"None\"]\n        - libgomp   # [linux]\n        - llvm-openmp    # [osx]\n        - intel-openmp {{ mkl }}  # [win]\n        - cmake\n        - ninja\n        # Keep libprotobuf here so that a compatibile version\n        # of protobuf is installed between build and host\n        - libprotobuf\n        - protobuf\n        - make      # [linux]\n        - sccache   # [win]\n      host:\n        # GPU requirements\n        - cudnn                           # [cuda_compiler_version != \"None\"]\n        - nccl                            # [cuda_compiler_version != \"None\" and linux]\n        - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version != \"None\"]\n        - nvtx-c                          # [cuda_compiler_version != \"None\"]\n        - magma                           # [cuda_compiler_version != \"None\"]\n        {% if cuda_compiler_version != \"None\" %}\n        - cuda-driver-dev                 # [linux]\n        - cuda-cudart-dev\n        - cuda-cupti-dev\n        - cuda-nvrtc-dev\n        - cuda-nvtx-dev\n        - cuda-nvml-dev\n        - cuda-profiler-api\n        - cusparselt\n        - libcublas-dev\n        - libcudss-dev\n        - libcufile-dev  # [linux]\n        - libcufft-dev\n        - libcurand-dev\n        - libcusolver-dev\n        - libcusparse-dev\n        {% endif %}\n        # other requirements\n        - python\n        - numpy\n        - pip\n        # see https://github.com/pytorch/pytorch/issues/136541\n        - setuptools <=72.1.0  # [win]\n        - setuptools  # [not win]\n        - pyyaml\n        - requests\n        - six\n        - mkl-devel {{ mkl }}   # [blas_impl == \"mkl\"]\n        - libcblas * *_mkl      # [blas_impl == \"mkl\"]\n        - libcblas              # [blas_impl != \"mkl\"]\n        - liblapack             # [blas_impl != \"mkl\"]\n        - libgomp   # [linux]\n        - llvm-openmp    # [osx]\n        - intel-openmp {{ mkl }}  # [win]\n        - libabseil\n        - libprotobuf\n        - sleef\n        - libuv\n        - pkg-config  # [unix]\n        - typing_extensions\n        - {{ pin_subpackage('libtorch', exact=True) }}\n        - pybind11\n        - eigen\n        - zlib\n      run:\n        - llvm-openmp    # [osx]\n        - intel-openmp {{ mkl }}  # [win]\n        - libblas * *{{ blas_impl }}  # [blas_impl == \"mkl\"]\n        # GPU requirements without run_exports\n        - {{ pin_compatible('cudnn') }}                       # [cuda_compiler_version != \"None\"]\n        # other requirements\n        - python\n        - typing_extensions\n        # sympy 1.13.2 was reported to result in test failures on Windows and mac\n        # https://github.com/pytorch/pytorch/pull/133235\n        - sympy >=1.13.1,!=1.13.2\n        - filelock\n        - jinja2\n        - networkx\n        - pybind11\n        - nomkl                 # [blas_impl != \"mkl\"]\n        - fsspec\n        # avoid that people without GPUs needlessly download ~0.5-1GB\n        - __cuda  # [cuda_compiler_version != \"None\"]\n        - libtorch {{ version }}\n        - setuptools\n        - triton {{ triton }}   # [cuda_compiler_version != \"None\" and not win]\n      run_constrained:\n        # These constraints ensure conflict between pytorch and\n        # pytorch-cpu 1.1 which we built before conda-forge had GPU infrastructure\n        # built into place.\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/65\n        - pytorch-cpu =={{ version }}  # [cuda_compiler_version == \"None\"]\n        - pytorch-gpu ==99999999       # [cuda_compiler_version == \"None\"]\n        - pytorch-gpu =={{ version }}  # [cuda_compiler_version != \"None\"]\n        - pytorch-cpu ==99999999       # [cuda_compiler_version != \"None\"]\n\n    test:\n      requires:\n        - {{ compiler('c') }}\n        - {{ compiler('cxx') }}\n        # for torch.compile tests\n        - {{ compiler('cuda') }}       # [cuda_compiler_version != \"None\"]\n        - ninja\n        - boto3\n        - hypothesis\n        - pytest\n        - tabulate\n        - pydot\n        - pip\n        - expecttest\n        - xmlrunner\n        # Required by run_test.py\n        - pytest-flakefinder\n        - pytest-rerunfailures\n        - pytest-xdist\n        # danpetry/TF: Pytorch includes their own edited version of pytest-shard and adding\n        # it into the test deps as well results in the --shard-id option being added twice.\n        # https://github.com/pytorch/pytorch/blob/main/test/pytest_shard_custom.py\n        # - pytest-shard\n      imports:\n        - torch\n      source_files:\n        # Only include the source_files if we are actually going to run the tests.\n        - test\n        # tools/ is needed to optimise test run\n        # as of pytorch=2.0.0, there is a bug when trying to run tests without the tools\n        - tools\n        #- .ci/pytorch/smoke_test/smoke_test.py\n      commands:\n        # Run pip check so as to ensure that all pytorch packages are installed\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/24\n        - pip check\n        - python -c \"import torch; print(torch.__version__)\"\n        - python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"  # [x86 and cuda_compiler_version == \"None\"]\n        - python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"\n        # We have had issues with openmp .dylibs being doubly loaded in certain cases. These two tests catch the (observed) issue\n        - python -c \"import torch; import numpy\"\n        - python -c \"import numpy; import torch\"\n        # distributed support is enabled by default on linux; for mac, we enable it manually in build.sh\n        - python -c \"import torch; assert torch.distributed.is_available()\"        # [linux or osx]\n        - python -c \"import torch; assert torch.backends.cuda.is_built()\"          # [linux64 and (cuda_compiler_version != \"None\")]\n        - python -c \"import torch; assert torch.backends.cudnn.is_available()\"     # [linux64 and (cuda_compiler_version != \"None\")]\n        - python -c \"import torch; assert torch.backends.cudnn.enabled\"            # [linux64 and (cuda_compiler_version != \"None\")]\n        # At conda-forge, we target versions of OSX that are too old for MPS support\n        # But if users install a newer version of OSX, they will have MPS support\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/pull/123#issuecomment-1186355073\n        # - python -c \"import torch; assert torch.backends.mps.is_available()\" # [osx]\n\n        # python-version-specific library (default location in SP_DIR symlinks back to this)\n        - test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}     # [unix]\n        - if not exist %LIBRARY_BIN%\\torch_python.dll exit 1  # [win]\n        - if not exist %LIBRARY_LIB%\\torch_python.lib exit 1  # [win]\n\n        # See here for environment variables needed by the smoke test script\n        # https://github.com/pytorch/pytorch/blob/266fd35c5842902f6304aa8e7713b252cbfb243c/.ci/pytorch/smoke_test/smoke_test.py#L16\n        - set MATRIX_GPU_ARCH_VERSION=\"{{ '.'.join((cuda_compiler_version or \"\").split('.')[:2]) }}\"   # [(cuda_compiler_version != \"None\") and (win)]\n        - set MATRIX_GPU_ARCH_TYPE=\"cuda\"                                                       # [(cuda_compiler_version != \"None\") and (win)]\n        - set MATRIX_GPU_ARCH_VERSION=\"none\"                                                    # [(cuda_compiler_version == \"None\") and (win)]\n        - set MATRIX_GPU_ARCH_TYPE=\"none\"                                                       # [(cuda_compiler_version == \"None\") and (win)]\n        - set MATRIX_CHANNEL=\"defaults\"                                                         # [win]\n        - set MATRIX_STABLE_VERSION={{ version }}                                               # [win]\n        - set MATRIX_PACKAGE_TYPE=\"conda\"                                                       # [win]\n        - set TARGET_OS=\"windows\"                                                               # [win]\n        - set OMP_NUM_THREADS=4                                                                 # [win]\n        - export MATRIX_GPU_ARCH_VERSION=\"{{ '.'.join((cuda_compiler_version or \"\").split('.')[:2]) }}\"  # [(cuda_compiler_version != \"None\") and (linux and x86_64)]\n        - export MATRIX_GPU_ARCH_TYPE=\"cuda\"                                                    # [(cuda_compiler_version != \"None\") and (linux and x86_64)]\n        - export MATRIX_GPU_ARCH_VERSION=\"none\"                                                 # [(cuda_compiler_version == \"None\") and (not win)]\n        - export MATRIX_GPU_ARCH_TYPE=\"none\"                                                    # [(cuda_compiler_version == \"None\") and (not win)]\n        - export MATRIX_CHANNEL=\"defaults\"                                                      # [not win]\n        - export MATRIX_STABLE_VERSION=\"{{ version }}\"                                          # [not win]\n        - export MATRIX_PACKAGE_TYPE=\"conda\"                                                    # [not win]\n        - export TARGET_OS=\"linux\"                                                              # [linux]\n        - export TARGET_OS=\"macos-arm64\"                                                        # [(osx and arm64)]\n        - export TARGET_OS=\"macos-x86_64\"                                                       # [(osx and x86_64)]\n        - export OMP_NUM_THREADS=4                                                              # [not win]\n        #- python ./smoke_test/smoke_test.py --package torchonly\n\n        # a reasonably safe subset of tests that should run under 15 minutes\n        {% set tests = \" \".join([\n            \"test/test_autograd.py\",\n            \"test/test_autograd_fallback.py\",\n            \"test/test_custom_ops.py\",\n            \"test/test_linalg.py\",\n            \"test/test_mkldnn.py\",\n            \"test/test_modules.py\",\n            \"test/test_nn.py\",\n            \"test/test_torch.py\",\n            \"test/test_xnnpack_integration.py\",\n        ]) %}\n        # tests torch.compile; avoid on aarch because it adds >4h in test runtime in emulation;\n        # they add a lot of runtime (15->60min on windows), so run them for only one python version\n        {% set tests = tests ~ \" test/inductor/test_torchinductor.py\" %}    # [py==312 and not aarch64]\n\n        {% set skips = \"(TestTorch and test_print)\" %}\n        # tolerance violation with openblas\n        {% set skips = skips ~ \" or test_1_sized_with_0_strided_cpu_float32\" %}         # [osx]\n        # timeouts and failures on aarch, see https://github.com/conda-forge/pytorch-cpu-feedstock/pull/298#issuecomment-2555888508\n        {% set skips = skips ~ \" or test_pynode_destruction_deadlock\" %}                # [aarch64]\n        {% set skips = skips ~ \" or (TestLinalgCPU and test_cholesky_cpu_float32)\" %}   # [aarch64]\n        {% set skips = skips ~ \" or (TestLinalgCPU and test_pca_lowrank_cpu)\" %}        # [aarch64]\n        {% set skips = skips ~ \" or (TestLinalgCPU and test_svd_lowrank_cpu)\" %}        # [aarch64]\n        {% set skips = skips ~ \" or (TestMkldnnCPU and test_lstm_cpu)\" %}               # [aarch64]\n        # dynamo does not support python 3.13\n        {% set skips = skips ~ \" or (TestCustomOp and test_data_dependent_compile)\" %}  # [py==313]\n        {% set skips = skips ~ \" or (TestCustomOp and test_functionalize_error)\" %}     # [py==313]\n        {% set skips = skips ~ \" or (TestCustomOpAPI and test_compile)\" %}              # [py==313]\n        {% set skips = skips ~ \" or (TestCustomOpAPI and test_fake)\" %}                 # [py==313]\n        {% set skips = skips ~ \" or test_compile_int4_mm or test_compile_int8_mm\" %}    # [py==313]\n        # doesn't crash, but gets different result on aarch + CUDA\n        {% set skips = skips ~ \" or illcondition_matrix_input_should_not_crash_cpu\" %}  # [aarch64 and cuda_compiler_version != \"None\"]\n        # may crash spuriously\n        {% set skips = skips ~ \" or (TestAutograd and test_profiler_seq_nr)\" %}\n        {% set skips = skips ~ \" or (TestAutograd and test_profiler_propagation)\" %}\n        # tests that fail due to resource clean-up issues (non-unique temporary libraries), see\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/pull/318#issuecomment-2620080859\n        {% set skips = skips ~ \" or test_mutable_custom_op_fixed_layout\" %}             # [cuda_compiler_version != \"None\"]\n        # trivial accuracy problems\n        {% set skips = skips ~ \" or test_BCELoss_weights_no_reduce_cuda\" %}             # [unix and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or test_ctc_loss_cudnn_tensor_cuda \" %}                # [unix and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or (TestTorch and test_index_add_correctness)\" %}      # [unix and cuda_compiler_version != \"None\"]\n        # These tests require higher-resource or more recent GPUs than the CI provides\n        {% set skips = skips ~ \" or test_sdpa_inference_mode_aot_compile\" %}            # [linux and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or (TestNN and test_grid_sample)\" %}                   # [linux and cuda_compiler_version != \"None\"]\n        # don't mess with tests that rely on GPU failure handling\n        {% set skips = skips ~ \" or test_indirect_device_assert\" %}                     # [linux and cuda_compiler_version != \"None\"]\n        # test that fails to find temporary resource\n        {% set skips = skips ~ \" or (GPUTests and test_scatter_reduce2)\" %}             # [linux and cuda_compiler_version != \"None\"]\n        # MKL problems\n        {% set skips = skips ~ \" or (TestLinalgCPU and test_inverse_errors_large_cpu)\" %}           # [linux and blas_impl == \"mkl\" and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or test_reentrant_parent_error_on_cpu_cuda)\" %}                    # [linux and blas_impl == \"mkl\" and cuda_compiler_version != \"None\"]\n        # non-MKL problems\n        {% set skips = skips ~ \" or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda\" %}   # [linux and blas_impl != \"mkl\" and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or test_cublas_config_nondeterministic_alert_cuda \" %}             # [linux and blas_impl != \"mkl\" and cuda_compiler_version != \"None\"]\n        # these tests are failing with low -n values\n        {% set skips = skips ~ \" or test_base_does_not_require_grad_mode_nothing\" %}\n        {% set skips = skips ~ \" or test_base_does_not_require_grad_mode_warn\" %}\n        {% set skips = skips ~ \" or test_composite_registered_to_cpu_mode_nothing\" %}\n        # these tests are failing on windows\n        {% set skips = skips ~ \" or (TestNN and test_Conv1d_dilated)\" %}                 # [win]\n        {% set skips = skips ~ \" or (TestNN and test_Conv1d_pad_same_dilated)\" %}        # [win]\n        {% set skips = skips ~ \" or (TestNN and test_Conv2d_pad_same_dilated)\" %}        # [win]\n        {% set skips = skips ~ \" or (TestNN and test_Conv2d_padding)\" %}                 # [win]\n        {% set skips = skips ~ \" or (TestNN and test_Conv2d_strided)\" %}                 # [win]\n        {% set skips = skips ~ \" or (TestNN and test_Conv3d_dilated)\" %}                 # [win]\n        {% set skips = skips ~ \" or (TestNN and test_Conv3d_dilated_strided)\" %}         # [win]\n        {% set skips = skips ~ \" or (TestNN and test_Conv3d_pad_same_dilated)\" %}        # [win]\n        {% set skips = skips ~ \" or (TestNN and test_Conv3d_stride)\" %}                  # [win]\n        {% set skips = skips ~ \" or (TestNN and test_Conv3d_stride_padding)\" %}          # [win]\n\n        # the whole test suite takes forever, but we should get a good enough coverage\n        # for potential packaging problems by running a fixed subset\n        - export OMP_NUM_THREADS=4  # [unix]\n        # reduced paralellism to avoid OOM; test only one python version on aarch because emulation is super-slow\n        # disable hypothesis because it randomly yields health check errors\n        - python -m pytest -n 2 {{ tests }} -k \"not ({{ skips }})\" -m \"not hypothesis\" --durations=50   # [unix and (not aarch64 or py==312)]\n        - python -m pytest -v -s {{ tests }} -k \"not ({{ skips }})\" -m \"not hypothesis\" --durations=50  # [win]\n\n        # regression test for https://github.com/conda-forge/pytorch-cpu-feedstock/issues/329, where we picked up\n        # duplicate `.pyc` files due to newest py-ver (3.13) in the build environment not matching the one in host;\n        # obviously this test can only be done for other python versions.\n        - test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc          # [py!=313 and unix]\n        - if exist %SP_DIR%\\functorch\\__pycache__\\__init__.cpython-313.pyc exit 1   # [py!=313 and win]\n\n  # 2021/08/01, hmaarrfk\n  # While this seems like a roundabout way of defining the package name\n  # It helps the linter avoid errors on a package not having tests.\n  {% set pytorch_cpu_gpu = \"pytorch-cpu\" %}   # [cuda_compiler_version == \"None\"]\n  {% set pytorch_cpu_gpu = \"pytorch-gpu\" %}   # [cuda_compiler_version != \"None\"]\n  - name: {{ pytorch_cpu_gpu }}\n    build:\n      string: cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                  # [megabuild and cuda_compiler_version != \"None\"]\n      string: cpu_{{ blas_impl }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                                # [megabuild and cuda_compiler_version == \"None\"]\n      string: cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}py{{ CONDA_PY }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [not megabuild and cuda_compiler_version != \"None\"]\n      string: cpu_{{ blas_impl }}_py{{ CONDA_PY }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                # [not megabuild and cuda_compiler_version == \"None\"]\n      detect_binary_files_with_prefix: false\n      # weigh down cpu implementation and give cuda preference\n      track_features:\n        - pytorch-cpu                                      # [cuda_compiler_version == \"None\"]\n    requirements:\n      run:\n        - pytorch {{ version }}=cuda*_{{ blas_impl }}*{{ PKG_BUILDNUM }}  # [megabuild and cuda_compiler_version != \"None\"]\n        - pytorch {{ version }}=cpu_{{ blas_impl }}*{{ PKG_BUILDNUM }}    # [megabuild and cuda_compiler_version == \"None\"]\n        - {{ pin_subpackage(\"pytorch\", exact=True) }}                     # [not megabuild]\n    test:\n      imports:\n        - torch\n\nabout:\n  home: https://pytorch.org/\n  dev_url: https://github.com/pytorch/pytorch\n  license: BSD-3-Clause\n  license_family: BSD\n  license_file:\n    - LICENSE\n    - NOTICE\n    - third_party/CMake/Copyright.txt\n  summary: PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.\n  description: |\n    PyTorch is a Python package that provides two high-level features:\n      - Tensor computation (like NumPy) with strong GPU acceleration\n      - Deep neural networks built on a tape-based autograd system\n    You can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n  doc_url: https://pytorch.org/docs/\n\nextra:\n  recipe-maintainers:\n    - baszalmstra\n    - benjaminrwilson\n    - beckermr\n    - h-vetinari\n    - hmaarrfk\n    - jeongseok-meta\n    - mgorny\n    - sodre\n    - Tobias-Fischer\n  feedstock-name: pytorch-cpu\n",
 "req": {
  "__set__": true,
  "elements": [
   "__cuda",
   "c_compiler_stub",
   "c_stdlib_stub",
   "cmake",
   "cuda-cudart-dev",
   "cuda-cupti-dev",
   "cuda-driver-dev",
   "cuda-nvml-dev",
   "cuda-nvrtc-dev",
   "cuda-nvtx-dev",
   "cuda-profiler-api",
   "cuda-version",
   "cuda_compiler_stub",
   "cudnn",
   "cusparselt",
   "cxx_compiler_stub",
   "eigen",
   "filelock",
   "fsspec",
   "intel-openmp",
   "jinja2",
   "libabseil",
   "libblas",
   "libcblas",
   "libcublas-dev",
   "libcudss-dev",
   "libcufft-dev",
   "libcufile-dev",
   "libcurand-dev",
   "libcusolver-dev",
   "libcusparse-dev",
   "libgomp",
   "liblapack",
   "libprotobuf",
   "libtorch",
   "libuv",
   "llvm-openmp",
   "magma",
   "make",
   "mkl-devel",
   "nccl",
   "networkx",
   "ninja",
   "nomkl",
   "numpy",
   "nvtx-c",
   "pip",
   "pkg-config",
   "protobuf",
   "pybind11",
   "python",
   "pytorch",
   "pyyaml",
   "requests",
   "rsync",
   "sccache",
   "setuptools",
   "six",
   "sleef",
   "sympy",
   "triton",
   "typing_extensions",
   "zlib"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "c_stdlib_stub",
    "cmake",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "intel-openmp",
    "libgomp",
    "libprotobuf",
    "libuv",
    "llvm-openmp",
    "make",
    "ninja",
    "protobuf",
    "python",
    "rsync",
    "sccache"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "c_stdlib_stub",
    "ctng-compilers",
    "cuda-cudart-dev",
    "cuda-cupti-dev",
    "cuda-driver-dev",
    "cuda-nvml-dev",
    "cuda-nvrtc-dev",
    "cuda-nvtx-dev",
    "cuda-profiler-api",
    "cuda-version",
    "cuda_compiler_stub",
    "cudnn",
    "cusparselt",
    "cxx_compiler_stub",
    "eigen",
    "intel-openmp",
    "libabseil",
    "libblas",
    "libcblas",
    "libcublas-dev",
    "libcudss-dev",
    "libcufft-dev",
    "libcufile-dev",
    "libcurand-dev",
    "libcusolver-dev",
    "libcusparse-dev",
    "libgomp",
    "liblapack",
    "libprotobuf",
    "libtorch",
    "libuv",
    "llvm-openmp",
    "magma",
    "mkl-devel",
    "nccl",
    "numpy",
    "nvtx-c",
    "openmp",
    "pip",
    "pkg-config",
    "pybind11",
    "python",
    "pyyaml",
    "requests",
    "setuptools",
    "six",
    "sleef",
    "typing_extensions",
    "zlib"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "__cuda",
    "c_compiler_stub",
    "c_stdlib_stub",
    "ctng-compilers",
    "cuda_compiler_stub",
    "cudnn",
    "cxx_compiler_stub",
    "filelock",
    "fsspec",
    "intel-openmp",
    "jinja2",
    "libblas",
    "libtorch",
    "llvm-openmp",
    "networkx",
    "nomkl",
    "openmp",
    "pybind11",
    "python",
    "pytorch",
    "setuptools",
    "sympy",
    "triton",
    "typing_extensions"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "boto3",
    "c_compiler_stub",
    "cmake",
    "cuda-nvrtc-dev",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "expecttest",
    "hypothesis",
    "ninja",
    "pip",
    "pkg-config",
    "pydot",
    "pytest",
    "pytest-flakefinder",
    "pytest-rerunfailures",
    "pytest-xdist",
    "tabulate",
    "xmlrunner"
   ]
  }
 },
 "strong_exports": false,
 "time": 1568135301.1552057,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "c_stdlib_stub",
    "cmake",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "intel-openmp <2025",
    "libgomp",
    "libprotobuf",
    "libuv",
    "llvm-openmp",
    "make",
    "ninja",
    "protobuf",
    "python",
    "rsync",
    "sccache"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cuda-cudart-dev",
    "cuda-cupti-dev",
    "cuda-driver-dev",
    "cuda-nvml-dev",
    "cuda-nvrtc-dev",
    "cuda-nvtx-dev",
    "cuda-profiler-api",
    "cuda-version 12.6",
    "cudnn",
    "cusparselt",
    "eigen",
    "intel-openmp <2025",
    "libabseil",
    "libblas",
    "libcblas",
    "libcblas * *_mkl",
    "libcublas-dev",
    "libcudss-dev",
    "libcufft-dev",
    "libcufile-dev",
    "libcurand-dev",
    "libcusolver-dev",
    "libcusparse-dev",
    "libgomp",
    "liblapack",
    "libprotobuf",
    "libtorch",
    "libuv",
    "llvm-openmp",
    "magma",
    "mkl-devel <2025",
    "nccl",
    "numpy",
    "numpy *",
    "nvtx-c",
    "pip",
    "pkg-config",
    "pybind11",
    "python",
    "python 3.12",
    "pyyaml",
    "requests",
    "setuptools",
    "setuptools <=72.1.0",
    "six",
    "sleef",
    "typing_extensions",
    "zlib"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "__cuda",
    "cudnn",
    "filelock",
    "fsspec",
    "intel-openmp <2025",
    "jinja2",
    "libblas * *mkl",
    "libtorch 2.5.1",
    "llvm-openmp",
    "networkx",
    "nomkl",
    "pybind11",
    "python",
    "pytorch",
    "pytorch 2.5.1=cpu_generic*12",
    "pytorch 2.5.1=cpu_mkl*112",
    "pytorch 2.5.1=cuda*_generic*212",
    "pytorch 2.5.1=cuda*_mkl*312",
    "setuptools",
    "sympy >=1.13.1,!=1.13.2",
    "triton 3.1.0",
    "typing_extensions"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "boto3",
    "c_compiler_stub",
    "cmake",
    "cuda-nvrtc-dev",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "expecttest",
    "hypothesis",
    "ninja",
    "pip",
    "pkg-config",
    "pydot",
    "pytest",
    "pytest-flakefinder",
    "pytest-rerunfailures",
    "pytest-xdist",
    "tabulate",
    "xmlrunner"
   ]
  }
 },
 "url": "https://github.com/pytorch/pytorch/releases/download/v2.5.1/pytorch-v2.5.1.tar.gz",
 "version": "2.5.1",
 "version_pr_info": {
  "__lazy_json__": "version_pr_info/pytorch-cpu.json"
 },
 "win_64_meta_yaml": {
  "about": {
   "description": "PyTorch is a Python package that provides two high-level features:\n  - Tensor computation (like NumPy) with strong GPU acceleration\n  - Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n",
   "dev_url": "https://github.com/pytorch/pytorch",
   "doc_url": "https://pytorch.org/docs/",
   "home": "https://pytorch.org/",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": [
    "LICENSE",
    "NOTICE",
    "third_party/CMake/Copyright.txt"
   ],
   "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
  },
  "build": {
   "detect_binary_files_with_prefix": false,
   "ignore_run_exports": [
    "python *",
    "numpy *",
    "libmagma_sparse"
   ],
   "ignore_run_exports_from": [
    "python *",
    "numpy *"
   ],
   "number": "312",
   "run_exports": [
    "libtorch"
   ],
   "skip": true,
   "string": "cuda126_mkl_h1234567_312"
  },
  "extra": {
   "feedstock-name": "pytorch-cpu",
   "recipe-maintainers": [
    "baszalmstra",
    "benjaminrwilson",
    "beckermr",
    "h-vetinari",
    "hmaarrfk",
    "jeongseok-meta",
    "mgorny",
    "sodre",
    "Tobias-Fischer"
   ]
  },
  "outputs": [
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cpu_mkl_py39_h1234567_112"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "intel-openmp <2025",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "sccache"
     ],
     "host": [
      "python",
      "numpy",
      "pip",
      "setuptools <=72.1.0",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "intel-openmp <2025",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "intel-openmp <2025",
      "libblas * *mkl",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-cpu ==2.5.1",
      "pytorch-gpu ==99999999"
     ]
    },
    "script": "bld.bat",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "if not exist %LIBRARY_BIN%\\torch_python.dll exit 1",
      "if not exist %LIBRARY_LIB%\\torch_python.lib exit 1",
      "set MATRIX_GPU_ARCH_VERSION=\"none\"",
      "set MATRIX_GPU_ARCH_TYPE=\"none\"",
      "set MATRIX_CHANNEL=\"defaults\"",
      "set MATRIX_STABLE_VERSION=2.5.1",
      "set MATRIX_PACKAGE_TYPE=\"conda\"",
      "set TARGET_OS=\"windows\"",
      "set OMP_NUM_THREADS=4",
      "python -m pytest -v -s test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "if exist %SP_DIR%\\functorch\\__pycache__\\__init__.cpython-313.pyc exit 1"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cpu_mkl_h1234567_112",
     "track_features": [
      "pytorch-cpu"
     ]
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cpu_mkl*112"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   },
   {
    "name": "libtorch"
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "ignore_run_exports": [
      "libmagma_sparse"
     ],
     "run_exports": [
      "pytorch",
      "libtorch"
     ],
     "string": "cuda126_mkl_py39_h1234567_312"
    },
    "name": "pytorch",
    "requirements": {
     "build": [
      "python",
      "c_stdlib_stub",
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "intel-openmp <2025",
      "cmake",
      "ninja",
      "libprotobuf",
      "protobuf",
      "sccache"
     ],
     "host": [
      "cudnn",
      "cuda-version 12.6",
      "nvtx-c",
      "magma",
      "cuda-cudart-dev",
      "cuda-cupti-dev",
      "cuda-nvrtc-dev",
      "cuda-nvtx-dev",
      "cuda-nvml-dev",
      "cuda-profiler-api",
      "cusparselt",
      "libcublas-dev",
      "libcudss-dev",
      "libcufft-dev",
      "libcurand-dev",
      "libcusolver-dev",
      "libcusparse-dev",
      "python",
      "numpy",
      "pip",
      "setuptools <=72.1.0",
      "pyyaml",
      "requests",
      "six",
      "mkl-devel <2025",
      "libcblas * *_mkl",
      "intel-openmp <2025",
      "libabseil",
      "libprotobuf",
      "sleef",
      "libuv",
      "typing_extensions",
      "libtorch",
      "pybind11",
      "eigen",
      "zlib"
     ],
     "run": [
      "intel-openmp <2025",
      "libblas * *mkl",
      "cudnn",
      "python",
      "typing_extensions",
      "sympy >=1.13.1,!=1.13.2",
      "filelock",
      "jinja2",
      "networkx",
      "pybind11",
      "fsspec",
      "__cuda",
      "libtorch 2.5.1",
      "setuptools"
     ],
     "run_constrained": [
      "pytorch-gpu ==2.5.1",
      "pytorch-cpu ==99999999"
     ]
    },
    "script": "bld.bat",
    "test": {
     "commands": [
      "pip check",
      "python -c \"import torch; print(torch.__version__)\"",
      "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
      "python -c \"import torch; import numpy\"",
      "python -c \"import numpy; import torch\"",
      "if not exist %LIBRARY_BIN%\\torch_python.dll exit 1",
      "if not exist %LIBRARY_LIB%\\torch_python.lib exit 1",
      "set MATRIX_GPU_ARCH_VERSION=\"12.6\"",
      "set MATRIX_GPU_ARCH_TYPE=\"cuda\"",
      "set MATRIX_CHANNEL=\"defaults\"",
      "set MATRIX_STABLE_VERSION=2.5.1",
      "set MATRIX_PACKAGE_TYPE=\"conda\"",
      "set TARGET_OS=\"windows\"",
      "set OMP_NUM_THREADS=4",
      "python -m pytest -v -s test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or (TestCustomOp and test_data_dependent_compile) or (TestCustomOp and test_functionalize_error) or (TestCustomOpAPI and test_compile) or (TestCustomOpAPI and test_fake) or test_compile_int4_mm or test_compile_int8_mm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda  or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_indirect_device_assert or (GPUTests and test_scatter_reduce2) or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_reentrant_parent_error_on_cpu_cuda) or test_cross_entropy_loss_2d_out_of_bounds_class_index_cuda or test_cublas_config_nondeterministic_alert_cuda  or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestNN and test_Conv1d_dilated) or (TestNN and test_Conv1d_pad_same_dilated) or (TestNN and test_Conv2d_pad_same_dilated) or (TestNN and test_Conv2d_padding) or (TestNN and test_Conv2d_strided) or (TestNN and test_Conv3d_dilated) or (TestNN and test_Conv3d_dilated_strided) or (TestNN and test_Conv3d_pad_same_dilated) or (TestNN and test_Conv3d_stride) or (TestNN and test_Conv3d_stride_padding))\" -m \"not hypothesis\" --durations=50",
      "if exist %SP_DIR%\\functorch\\__pycache__\\__init__.cpython-313.pyc exit 1"
     ],
     "imports": [
      "torch"
     ],
     "requires": [
      "c_compiler_stub",
      "cxx_compiler_stub",
      "cuda_compiler_stub",
      "ninja",
      "boto3",
      "hypothesis",
      "pytest",
      "tabulate",
      "pydot",
      "pip",
      "expecttest",
      "xmlrunner",
      "pytest-flakefinder",
      "pytest-rerunfailures",
      "pytest-xdist"
     ],
     "source_files": [
      "test",
      "tools"
     ]
    }
   },
   {
    "build": {
     "detect_binary_files_with_prefix": false,
     "string": "cuda126_mkl_h1234567_312",
     "track_features": null
    },
    "name": "pytorch-gpu",
    "requirements": {
     "run": [
      "pytorch 2.5.1=cuda*_mkl*312"
     ]
    },
    "test": {
     "imports": [
      "torch"
     ]
    }
   }
  ],
  "package": {
   "name": "libtorch",
   "version": "2.5.1"
  },
  "requirements": {
   "build": [
    "c_stdlib_stub",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "intel-openmp <2025",
    "libuv",
    "cmake",
    "ninja",
    "libprotobuf",
    "protobuf",
    "sccache",
    "cuda_compiler_stub"
   ],
   "host": [
    "python 3.12",
    "numpy *",
    "pip",
    "setuptools <=72.1.0",
    "pyyaml",
    "requests",
    "six",
    "mkl-devel <2025",
    "libcblas * *_mkl",
    "intel-openmp <2025",
    "libabseil",
    "libprotobuf",
    "sleef",
    "libuv",
    "typing_extensions",
    "pybind11",
    "eigen",
    "zlib",
    "cudnn",
    "magma",
    "cuda-version 12.6",
    "nvtx-c",
    "cuda-cudart-dev",
    "cuda-cupti-dev",
    "cuda-nvrtc-dev",
    "cuda-nvtx-dev",
    "cuda-nvml-dev",
    "cuda-profiler-api",
    "cusparselt",
    "libcublas-dev",
    "libcudss-dev",
    "libcufft-dev",
    "libcurand-dev",
    "libcusolver-dev",
    "libcusparse-dev"
   ],
   "run": [
    "intel-openmp <2025",
    "libblas * *mkl",
    "cudnn"
   ],
   "run_constrained": [
    "pytorch-cpu ==2.5.1",
    "pytorch-gpu ==99999999",
    "pytorch 2.5.1 cpu_mkl_*_112",
    "pytorch-gpu ==2.5.1",
    "pytorch-cpu ==99999999",
    "pytorch 2.5.1 cuda126_mkl_*_312"
   ]
  },
  "schema_version": 0,
  "source": {
   "patches": [
    "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
    "patches/0002-Help-find-numpy.patch",
    "patches/0003-Add-USE_SYSTEM_NVTX-option-138287.patch",
    "patches/0004-Update-sympy-version.patch",
    "patches/0006-fix-3.13-pickle-error-in-serialization.py-136034.patch",
    "patches/0007-Allow-users-to-overwrite-ld-with-environment-variabl.patch",
    "patches/0008-Allow-overriding-CUDA-related-paths.patch",
    "patches/0009-Fix-test-test_linalg.py-for-NumPy-2-136800.patch",
    "patches/0010-Fixes-NumPy-2-test-failures-in-test_torch.py-137740.patch",
    "patches/0011-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
    "patches/0012-fix-issue-142484.patch",
    "patches/0013-Fix-FindOpenBLAS.patch",
    "patches/0014-CD-Enable-Python-3.13-on-windows-138095.patch",
    "patches/0015-simplify-torch.utils.cpp_extension.include_paths-use.patch",
    "patches/0016-point-include-paths-to-PREFIX-include.patch",
    "patches/0017-Add-conda-prefix-to-inductor-include-paths.patch",
    "patches/0018-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
    "patches/0019-remove-DESTINATION-lib-from-CMake-install-TARGETS-di.patch",
    "patches/0020-make-library-name-in-test_mutable_custom_op_fixed_la.patch",
    "patches/0021-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
    "patches_submodules/fbgemm/0001-remove-DESTINATION-lib-from-CMake-install-directives.patch",
    "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
   ],
   "sha256": "740eb5fff95e33cfe699bad43be83523f569c7cc7f9c285c2a255416443dd266",
   "url": "https://github.com/pytorch/pytorch/releases/download/v2.5.1/pytorch-v2.5.1.tar.gz"
  },
  "test": {
   "commands": [
    "if not exist %LIBRARY_BIN%\\c10.dll exit 1",
    "if not exist %LIBRARY_LIB%\\c10.lib exit 1",
    "if not exist %LIBRARY_BIN%\\shm.dll exit 1",
    "if not exist %LIBRARY_LIB%\\shm.lib exit 1",
    "if not exist %LIBRARY_BIN%\\torch.dll exit 1",
    "if not exist %LIBRARY_LIB%\\torch.lib exit 1",
    "if not exist %LIBRARY_BIN%\\torch_cpu.dll exit 1",
    "if not exist %LIBRARY_LIB%\\torch_cpu.lib exit 1",
    "if not exist %LIBRARY_BIN%\\torch_global_deps.dll exit 1",
    "if not exist %LIBRARY_BIN%\\asmjit.dll exit 1",
    "if not exist %LIBRARY_LIB%\\asmjit.lib exit 1",
    "if not exist %LIBRARY_BIN%\\fbgemm.dll exit 1",
    "if not exist %LIBRARY_LIB%\\fbgemm.lib exit 1",
    "if not exist %LIBRARY_PREFIX%\\share\\cmake\\Torch\\TorchConfig.cmake exit 1",
    "cd cmake_test",
    "cmake -GNinja -DCMAKE_CXX_STANDARD=17 %CMAKE_ARGS% .",
    "if not exist %LIBRARY_BIN%\\c10_cuda.dll exit 1",
    "if not exist %LIBRARY_LIB%\\c10_cuda.lib exit 1",
    "if not exist %LIBRARY_BIN%\\caffe2_nvrtc.dll exit 1",
    "if not exist %LIBRARY_LIB%\\caffe2_nvrtc.lib exit 1",
    "if not exist %LIBRARY_BIN%\\torch_cuda.dll exit 1",
    "if not exist %LIBRARY_LIB%\\torch_cuda.lib exit 1"
   ],
   "files": [
    "cmake_test/"
   ],
   "requires": [
    "cxx_compiler_stub",
    "cmake",
    "ninja",
    "pkg-config",
    "cuda_compiler_stub",
    "cuda-nvrtc-dev"
   ]
  }
 },
 "win_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "c_stdlib_stub",
    "cmake",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "intel-openmp",
    "libprotobuf",
    "libuv",
    "ninja",
    "protobuf",
    "python",
    "sccache"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "cuda-cudart-dev",
    "cuda-cupti-dev",
    "cuda-nvml-dev",
    "cuda-nvrtc-dev",
    "cuda-nvtx-dev",
    "cuda-profiler-api",
    "cuda-version",
    "cudnn",
    "cusparselt",
    "eigen",
    "intel-openmp",
    "libabseil",
    "libcblas",
    "libcublas-dev",
    "libcudss-dev",
    "libcufft-dev",
    "libcurand-dev",
    "libcusolver-dev",
    "libcusparse-dev",
    "libprotobuf",
    "libtorch",
    "libuv",
    "magma",
    "mkl-devel",
    "numpy",
    "nvtx-c",
    "pip",
    "pybind11",
    "python",
    "pyyaml",
    "requests",
    "setuptools",
    "six",
    "sleef",
    "typing_extensions",
    "zlib"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "__cuda",
    "cudnn",
    "filelock",
    "fsspec",
    "intel-openmp",
    "jinja2",
    "libblas",
    "libtorch",
    "networkx",
    "pybind11",
    "python",
    "pytorch",
    "setuptools",
    "sympy",
    "typing_extensions"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "boto3",
    "c_compiler_stub",
    "cmake",
    "cuda-nvrtc-dev",
    "cuda_compiler_stub",
    "cxx_compiler_stub",
    "expecttest",
    "hypothesis",
    "ninja",
    "pip",
    "pkg-config",
    "pydot",
    "pytest",
    "pytest-flakefinder",
    "pytest-rerunfailures",
    "pytest-xdist",
    "tabulate",
    "xmlrunner"
   ]
  }
 }
}